---
title: "Analysis of Human Breast Cancer Cells"
author: "Kelsey Dang"
date: "10/29/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# 1. Exploratory Data Analysis

```{r}
wisc.df <- read.csv("WisconsinCancer.csv")
head(wisc.df)
```

Now, see how many patients we have.
```{r}
nrow(wisc.df)
```

How many patients are malignant?
```{r}
table(wisc.df$diagnosis)
```

Creating wisc.data
```{r}
# Convert the features of the data: wisc.data
wisc.data <- as.matrix(wisc.df[,3:32])

# Set the row names of wisc.data
row.names(wisc.data) <- wisc.df$id
head(wisc.data)
```

Store the diagnosis for reference in the future as a separate vector

```{r}
# Create diagnosis vector for later 
diagnosis <- wisc.df$diagnosis
```

Q1. How many observations are in this dataset?
```{r}
nrow(wisc.df)
```

Q2. How many of the observations have a malignant diagnosis?
```{r}
table(wisc.df$diagnosis)
```

Q3. How many variables/features in the data are suffixed with _mean?
```{r}
grep("_mean", colnames(wisc.df), value = TRUE)
```

Use *length* to see the length
```{r}
length(grep("_mean", colnames(wisc.df), value = TRUE))
```

# 2. Principal Component Analysis

## Performing PCA
The next step in your analysis is to perform principal component analysis (PCA) on wisc.data.

It is important to check if the data need to be scaled before performing PCA. Recall two common reasons for scaling data include:  
  * The input variables use different units of measurement  
  * The input variables have significantly different variances  

Check the mean and standard deviation of the features (i.e. columns) of the wisc.data to determine if the data should be scaled. Use the colMeans() and apply() functions like you’ve done before.
```{r}
# Check column means and standard deviations
colMeans(wisc.data)

apply(wisc.data,2,sd)
```

```{r}
round(apply(wisc.data, 2, sd), 3)
```

These values look very different so I will use **scale=TRUE** when I run PCA
```{r}
# Perform PCA on wisc.data by completing the following code
wisc.pr <- prcomp( wisc.data, scale = TRUE )
summary(wisc.pr)
```

## Interpreting PCA results

PC1 v. PC2 plot

Color by cancer/non-cancer
```{r}
plot(wisc.pr$x[,1], wisc.pr$x[,2], col=diagnosis)
```

You can see the split between cancerous and non-cancerous!

Q4. From your results, what proportion of the original variance is captured by the first principal components (PC1)?  
```{r}
x <- summary(wisc.pr)
x$importance[,1]
# By using importance can print out a specific col/row
# 0.4427
```

Q5. How many principal components (PCs) are required to describe at least 70% of the original variance in the data?
```{r}
which(x$importance[3,] > 0.7)[1]
```

Q6. How many principal components (PCs) are required to describe at least 90% of the original variance in the data?
```{r}
which(x$importance[3,] > 0.9)[1]
```

## Communicating PCA Results
In this section we will check your understanding of the PCA results, in particular the loadings and variance explained. The loadings, represented as vectors, explain the mapping from the original features to the principal components. The principal components are naturally ordered from the most variance explained to the least variance explained.

Q9. For the first principal component, what is the component of the loading vector (i.e. wisc.pr$rotation[,1]) for the feature concave.points_mean?

```{r}
wisc.pr$rotation["concave.points_mean",1]
```


Q10. What is the minimum number of principal components required to explain 80% of the variance of the data?

```{r}
x <- summary(wisc.pr)
which(x$importance["Cumulative Proportion",] > 0.8)[1]
```


# 3. Hierarchical Clustering
## Hierarchical clustering of case data

The goal of this section is to do hierarchical clustering of the observations. Recall from our last class that this type of clustering does not assume in advance the number of natural groups that exist in the data.

As part of the preparation for hierarchical clustering, the distance between all pairs of observations are computed. Furthermore, there are different ways to link clusters together, with single, complete, and average being the most common linkage methods.

Scale the wisc.data data and assign the result to data.scaled.

```{r}
# Scale the wisc.data data: data.scaled
data.scaled <- scale(wisc.data)

```

Calculate the Euclidean distances between all pairs of observations.
```{r}
data.dist <- dist(data.scaled)
```

Create a hierarchical clustering model using complete linkage
```{r}
wisc.hclust <- hclust(data.dist, method = "complete")
wisc.hclust
```

## Results of Hierarchical Clustering

Let’s use the hierarchical clustering model you just created to determine a height (or distance between clusters) where a certain number of clusters exists.

Q11. Using the plot() and abline() functions, what is the height at which the clustering model has 4 clusters?

```{r}
plot(wisc.hclust)
abline(wisc.hclust, col="red", lty=2)
```

Use cutree() to cut the tree so that it has 4 clusters. Assign the output to the variable wisc.hclust.clusters.
```{r}
wisc.hclust.clusters <- cutree(wisc.hclust, k=4)
table(wisc.hclust.clusters, diagnosis)
```

Q12. Can you find a better cluster vs diagnoses match with by cutting into a different number of clusters between 2 and 10?

# 4. K-means Clustering

In this section, you will create a k-means clustering model on the Wisconsin breast cancer data and compare the results to the actual diagnoses and the results of your hierarchical clustering model. Take some time to see how each clustering model performs in terms of separating the two diagnoses and how the clustering models compare to each other.  
  
Create a k-means model on wisc.data, assigning the result to wisc.km. Be sure to create 2 clusters, corresponding to the actual number of diagnosis. Also, remember to scale the data (with the scale() function and repeat the algorithm 20 times (by setting setting the value of the nstart argument appropriately). Running multiple times such as this will help to find a well performing model.  




# 5. Combining Methods

# 6. Sensitivity/Specificity

# 7. Prediction

```{r}
#url <- "new_samples.csv"
url <- "https://tinyurl.com/new-samples-CSV"
new <- read.csv(url)
npc <- predict(wisc.pr, newdata=new)
npc
```

```{r}
plot(wisc.pr$x[,1], wisc.pr$x[,2], col=diagnosis)
points(npc[,1], npc[,2], col="blue", pch=16, cex=3)
text(npc[,1], npc[,2], c(1,2), col="white")
```

Q17. Which of these new patients should we prioritize for follow up based on your results?
Patient 2

# 8. 






